# Automated Short Answer Grading Experiments
===========

Code for the paper
> Torsten Zesch, Michael Heilman, and Aoife Cahill.
> Reducing Annotation Efforts in Supervised Short Answer Scoring
> In Proceedings of 10th Building Educational Applications (BEA) Workshop at NAACL, 2015.

## Abstract
Automated short answer scoring is increas- ingly used to give students timely feedback about their learning progress. Building scor- ing models comes with high costs, as state-of-the-art methods using supervised learning require large amounts of hand-annotated data. We analyze the potential of recently proposed methods for semi-supervised learning based on clustering. We find that all examined meth- ods (centroids, all clusters, selected pure clus- ters) are mainly effective for very short answers and do not generalize well to several-sentence responses.
